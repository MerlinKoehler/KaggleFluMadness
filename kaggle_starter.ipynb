{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEN3450, Data Analysis 2020 \n",
    "\n",
    "**Kaggle Competition 2020**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math\n",
    "import re\n",
    "#import your classifiers here\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 500\n",
    "# References https://stackoverflow.com/questions/46543060/how-to-replace-every-nan-in-a-column-with-different-random-values-using-pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnosing the Maastricht Flu \n",
    "\n",
    "You are given the early data for an outbreak of a dangerous virus originating from a group of primates being kept in a Maastricht biomedical research lab in the basement of Henri-Paul Spaaklaan building, this virus is dubbed the \"Maastricht Flu\".\n",
    "\n",
    "You have the medical records of $n$ number of patients in `flu_train.csv`. There are two general types of patients in the data, flu patients and healthy (this is recorded in the column labeled `flu`, a 0 indicates the absences of the virus and a 1 indicates presence). Notice that the dataset is unbalanced and you can expect a similar imbalance in the testing set.\n",
    "\n",
    "**Your task:** build a model to predict if a given patient has the flu. Your goal is to catch as many flu patients as possible without misdiagnosing too many healthy patients.\n",
    "\n",
    "**The deliverable:** submit your final solution via Kaggle competition using the `flu_test.csv` data.\n",
    "\n",
    "Maastricht Gemeente will use your model to diagnose sets of future patients (held by us). You can expect that there will be an increase in the number of flu patients in any groups of patients in the future.\n",
    "\n",
    "Here are some benchmarks for comparison and for expectation management. Notice that because the dataset is unbalanced, we expect that there is going to be a large difference in the accuracy for each class, thus `accuracy` is a metric that might be misleading in this case (see also below). That's why the baselines below are based on the expected accuracy **per class** and also they give you an estimate for the AUROC on all patients in the testing data. This is the score you see in the Kaggle submission as well.\n",
    "\n",
    "**Baseline Model:** \n",
    "- ~50% expected accuracy on healthy patients in training data\n",
    "- ~50% expected accuracy on flu patients in training data\n",
    "- ~50% expected accuracy on healthy patients in testing data (future data, no info on the labels)\n",
    "- ~50% expected accuracy on flu patients in testing data (future data, no info on the labels)\n",
    "- ~50% expected AUROC on all patients in testing data (future data, no info on the labels)\n",
    "\n",
    "**Reasonable Model:** \n",
    "- ~70% expected accuracy on healthy patients in training data\n",
    "- ~55% expected accuracy on flu patients, in training data\n",
    "- ~70% expected accuracy on healthy patients in testing data (future data, no info on the labels, to be checked upon your submission)\n",
    "- ~57% expected accuracy on flu patients, in testing data (future data, no info on the labels, to be checked upon your submission)\n",
    "- ~65% expected AUROC on all patients, in testing data (future data, no info on the labels, to be checked from Kaggle)\n",
    "\n",
    "**Grading:**\n",
    "Your grade will be based on:\n",
    "1. your model's ability to out-perform the benchmarks (they are kind of low, so we won't care much about this)\n",
    "2. your ability to carefully and thoroughly follow the data analysis pipeline\n",
    "3. the extend to which all choices are reasonable and defensible by methods you have learned in this class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read the data, clean and explore the data\n",
    "\n",
    "There are a large number of missing values in the data. Nearly all predictors have some degree of missingness. Not all missingness are alike: NaN in the `'pregnancy'` column is meaningful and informative, as patients with NaN's in the pregnancy column are males, where as NaN's in other predictors may appear randomly. \n",
    "\n",
    "\n",
    "**What do you do?:** We make no attempt to interpret the predictors and we make no attempt to model the missing values in the data in any meaningful way. We replace all missing values with 0.\n",
    "\n",
    "However, it would be more complete to look at the data and allow the data to inform your decision on how to address missingness. For columns where NaN values are informative, you might want to treat NaN as a distinct value; You might want to drop predictors with too many missing values and impute the ones with few missing values using a model. There are many acceptable strategies here, as long as the appropriateness of the method in the context of the task and the data is discussed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "def fillNaN_with_unifrand(df):\n",
    "    a = df.values\n",
    "    m = np.isnan(a) # mask of NaNs\n",
    "    mu, sigma = df.mean(), df.std()\n",
    "    a[m] = np.random.normal(mu, sigma, size=m.sum())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "df = pd.read_csv('data/flu_train.csv')\n",
    "df = df[~np.isnan(df['flu'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4564 entries, 0 to 5245\n",
      "Data columns (total 64 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               4564 non-null   int64  \n",
      " 1   Gender           4564 non-null   int64  \n",
      " 2   Age              4564 non-null   int64  \n",
      " 3   Race1            4564 non-null   object \n",
      " 4   Education        4564 non-null   object \n",
      " 5   MaritalStatus    4564 non-null   object \n",
      " 6   HHIncomeMid      4564 non-null   float64\n",
      " 7   Poverty          4564 non-null   float64\n",
      " 8   HomeRooms        4564 non-null   float64\n",
      " 9   HomeOwn          4564 non-null   object \n",
      " 10  Work             4564 non-null   object \n",
      " 11  Weight           4564 non-null   float64\n",
      " 12  Height           4564 non-null   float64\n",
      " 13  BMI              4564 non-null   float64\n",
      " 14  Pulse            4564 non-null   float64\n",
      " 15  BPSysAve         4564 non-null   float64\n",
      " 16  BPDiaAve         4564 non-null   float64\n",
      " 17  BPSys1           4564 non-null   float64\n",
      " 18  BPDia1           4564 non-null   float64\n",
      " 19  BPSys2           4564 non-null   float64\n",
      " 20  BPDia2           4564 non-null   float64\n",
      " 21  BPSys3           4564 non-null   float64\n",
      " 22  BPDia3           4564 non-null   float64\n",
      " 23  Testosterone     4564 non-null   float64\n",
      " 24  DirectChol       4564 non-null   float64\n",
      " 25  TotChol          4564 non-null   float64\n",
      " 26  UrineVol1        4564 non-null   float64\n",
      " 27  UrineFlow1       4564 non-null   float64\n",
      " 28  Diabetes         4564 non-null   int64  \n",
      " 29  HealthGen        4564 non-null   object \n",
      " 30  DaysMentHlthBad  4564 non-null   float64\n",
      " 31  LittleInterest   4564 non-null   object \n",
      " 32  Depressed        4564 non-null   object \n",
      " 33  nPregnancies     4564 non-null   float64\n",
      " 34  nBabies          4564 non-null   float64\n",
      " 35  Age1stBaby       4564 non-null   float64\n",
      " 36  SleepHrsNight    4564 non-null   float64\n",
      " 37  SleepTrouble     4564 non-null   int64  \n",
      " 38  PhysActive       4564 non-null   int64  \n",
      " 39  PhysActiveDays   4564 non-null   float64\n",
      " 40  TVHrsDay         4564 non-null   float64\n",
      " 41  CompHrsDay       4564 non-null   float64\n",
      " 42  TVHrsDayChild    4564 non-null   float64\n",
      " 43  CompHrsDayChild  4564 non-null   float64\n",
      " 44  Alcohol12PlusYr  4564 non-null   int64  \n",
      " 45  AlcoholDay       4564 non-null   float64\n",
      " 46  AlcoholYear      4564 non-null   float64\n",
      " 47  SmokeNow         4564 non-null   int64  \n",
      " 48  Smoke100         4564 non-null   int64  \n",
      " 49  Smoke100n        4564 non-null   object \n",
      " 50  SmokeAge         4564 non-null   float64\n",
      " 51  Marijuana        4564 non-null   int64  \n",
      " 52  AgeFirstMarij    4564 non-null   float64\n",
      " 53  RegularMarij     4564 non-null   int64  \n",
      " 54  AgeRegMarij      4564 non-null   float64\n",
      " 55  HardDrugs        4564 non-null   int64  \n",
      " 56  SexEver          4564 non-null   int64  \n",
      " 57  SexAge           4564 non-null   float64\n",
      " 58  SexNumPartnLife  4564 non-null   float64\n",
      " 59  SexNumPartYear   4564 non-null   float64\n",
      " 60  SameSex          4564 non-null   int64  \n",
      " 61  SexOrientation   4564 non-null   object \n",
      " 62  PregnantNow      4564 non-null   int64  \n",
      " 63  flu              4564 non-null   int64  \n",
      "dtypes: float64(38), int64(16), object(10)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                 0\n",
       "Gender             0\n",
       "Age                0\n",
       "Race1              0\n",
       "Education          0\n",
       "MaritalStatus      0\n",
       "HHIncomeMid        0\n",
       "Poverty            0\n",
       "HomeRooms          0\n",
       "HomeOwn            0\n",
       "Work               0\n",
       "Weight             0\n",
       "Height             0\n",
       "BMI                0\n",
       "Pulse              0\n",
       "BPSysAve           0\n",
       "BPDiaAve           0\n",
       "BPSys1             0\n",
       "BPDia1             0\n",
       "BPSys2             0\n",
       "BPDia2             0\n",
       "BPSys3             0\n",
       "BPDia3             0\n",
       "Testosterone       0\n",
       "DirectChol         0\n",
       "TotChol            0\n",
       "UrineVol1          0\n",
       "UrineFlow1         0\n",
       "Diabetes           0\n",
       "HealthGen          0\n",
       "DaysMentHlthBad    0\n",
       "LittleInterest     0\n",
       "Depressed          0\n",
       "nPregnancies       0\n",
       "nBabies            0\n",
       "Age1stBaby         0\n",
       "SleepHrsNight      0\n",
       "SleepTrouble       0\n",
       "PhysActive         0\n",
       "PhysActiveDays     0\n",
       "TVHrsDay           0\n",
       "CompHrsDay         0\n",
       "TVHrsDayChild      0\n",
       "CompHrsDayChild    0\n",
       "Alcohol12PlusYr    0\n",
       "AlcoholDay         0\n",
       "AlcoholYear        0\n",
       "SmokeNow           0\n",
       "Smoke100           0\n",
       "Smoke100n          0\n",
       "SmokeAge           0\n",
       "Marijuana          0\n",
       "AgeFirstMarij      0\n",
       "RegularMarij       0\n",
       "AgeRegMarij        0\n",
       "HardDrugs          0\n",
       "SexEver            0\n",
       "SexAge             0\n",
       "SexNumPartnLife    0\n",
       "SexNumPartYear     0\n",
       "SameSex            0\n",
       "SexOrientation     0\n",
       "PregnantNow        0\n",
       "flu                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned_train = df.copy()\n",
    "\n",
    "# Changed Male/Female to 1/0 for a boolean datatype\n",
    "df_cleaned_train.loc[(df_cleaned_train['Gender'] == 'male'), 'Gender'] = 1\n",
    "df_cleaned_train.loc[(df_cleaned_train['Gender'] == 'female'), 'Gender'] = 0\n",
    "df_cleaned_train.dropna(subset=['Gender'], inplace=True)\n",
    "\n",
    "# Age of 0 is okay, we assume this are babies.\n",
    "#display(df_cleaned_train[df_cleaned_train['Age'] == 0]['Weight'].describe())\n",
    "\n",
    "\n",
    "# Set everybody under age of 14 to No Degree\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Education'])) & (df_cleaned_train['Age'] < 14), 'Education'] = 'No Degree'\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Education'])), 'Education'] = 'Unknown'\n",
    "\n",
    "# Set Marital Status to unknown for the missing values\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['MaritalStatus'])), 'MaritalStatus'] = 'Unknown'\n",
    "\n",
    "# Delete all rows where HHIncome is nan\n",
    "df_cleaned_train.dropna(subset=['HHIncomeMid'], inplace=True)\n",
    "\n",
    "#df_cleaned_train[pd.isna(df_cleaned_train['Poverty'])]\n",
    "#df_cleaned_train.plot.scatter(y = 'Poverty', x='HHIncomeMid')\n",
    "# Deleting missing poverty values for now, if it is import we can do a lin reg later on.\n",
    "df_cleaned_train.loc[(df_cleaned_train['Poverty'] == 0) & (df_cleaned_train['HHIncome'] == 'more 99999'), 'Poverty'] = math.nan\n",
    "df_cleaned_train.dropna(subset=['Poverty'], inplace=True)\n",
    "\n",
    "del df_cleaned_train['HHIncome']\n",
    "#display(df_cleaned_train[df_cleaned_train['Poverty'] == 0])\n",
    "\n",
    "\n",
    "df_cleaned_train.dropna(subset=['HomeRooms'], inplace=True)\n",
    "df_cleaned_train.dropna(subset=['HomeOwn'], inplace=True)\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Work'])), 'Work'] = 'Unknown'\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Weight'])) & (df_cleaned_train.flu == 1), 'Weight'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['Weight'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Weight'])) & (df_cleaned_train.flu == 0), 'Weight'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['Weight'])\n",
    "\n",
    "\n",
    "# Height and Length describe the same values, so we copy it from one to the other.\n",
    "df_cleaned_train.loc[((pd.notna(df_cleaned_train.Length)) & (pd.isna(df_cleaned_train.Height))), 'Height'] = df_cleaned_train[(pd.notna(df_cleaned_train.Length)) & (pd.isna(df_cleaned_train.Height))][['Length']]\n",
    "df_cleaned_train.dropna(subset=['Height'], inplace=True)\n",
    "del df_cleaned_train['Length']\n",
    "\n",
    "del df_cleaned_train['HeadCirc']\n",
    "del df_cleaned_train['BMICatUnder20yrs']\n",
    "del df_cleaned_train['BMI_WHO']\n",
    "df_cleaned_train.dropna(subset=['BMI'], inplace=True)\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Pulse'])) & (df_cleaned_train.flu == 1), 'Pulse'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['Pulse'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Pulse'])) & (df_cleaned_train.flu == 0), 'Pulse'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['Pulse'])\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPSysAve'])) & (df_cleaned_train.flu == 1), 'BPSysAve'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['BPSysAve'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPSysAve'])) & (df_cleaned_train.flu == 0), 'BPSysAve'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['BPSysAve'])\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPDiaAve'])) & (df_cleaned_train.flu == 1), 'BPDiaAve'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['BPDiaAve'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPDiaAve'])) & (df_cleaned_train.flu == 0), 'BPDiaAve'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['BPDiaAve'])\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPSys1'])) & (df_cleaned_train.flu == 1), 'BPSys1'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['BPSys1'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPSys1'])) & (df_cleaned_train.flu == 0), 'BPSys1'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['BPSys1'])\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPDia1'])) & (df_cleaned_train.flu == 1), 'BPDia1'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['BPDia1'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPDia1'])) & (df_cleaned_train.flu == 0), 'BPDia1'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['BPDia1'])\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPSys2'])) & (df_cleaned_train.flu == 1), 'BPSys2'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['BPSys2'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPSys2'])) & (df_cleaned_train.flu == 0), 'BPSys2'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['BPSys2'])\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPDia2'])) & (df_cleaned_train.flu == 1), 'BPDia2'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['BPDia2'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPDia2'])) & (df_cleaned_train.flu == 0), 'BPDia2'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['BPDia2'])\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPSys3'])) & (df_cleaned_train.flu == 1), 'BPSys3'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['BPSys3'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPSys3'])) & (df_cleaned_train.flu == 0), 'BPSys3'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['BPSys3'])\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPDia3'])) & (df_cleaned_train.flu == 1), 'BPDia3'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['BPDia3'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['BPDia3'])) & (df_cleaned_train.flu == 0), 'BPDia3'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['BPDia3'])\n",
    "\n",
    "df_cleaned_train.Testosterone = df_cleaned_train.Testosterone.astype(float)\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Testosterone'])) & (df_cleaned_train.flu == 1), 'Testosterone'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['Testosterone'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Testosterone'])) & (df_cleaned_train.flu == 0), 'Testosterone'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['Testosterone'])\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['DirectChol'])) & (df_cleaned_train.flu == 1), 'DirectChol'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['DirectChol'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['DirectChol'])) & (df_cleaned_train.flu == 0), 'DirectChol'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['DirectChol'])\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['TotChol'])) & (df_cleaned_train.flu == 1), 'TotChol'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['TotChol'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['TotChol'])) & (df_cleaned_train.flu == 0), 'TotChol'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['TotChol'])\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['UrineVol1'])) & (df_cleaned_train.flu == 1), 'UrineVol1'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['UrineVol1'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['UrineVol1'])) & (df_cleaned_train.flu == 0), 'UrineVol1'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['UrineVol1'])\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['UrineFlow1'])) & (df_cleaned_train.flu == 1), 'UrineFlow1'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['UrineFlow1'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['UrineFlow1'])) & (df_cleaned_train.flu == 0), 'UrineFlow1'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['UrineFlow1'])\n",
    "\n",
    "del df_cleaned_train['UrineVol2']\n",
    "del df_cleaned_train['UrineFlow2']\n",
    "\n",
    "df_cleaned_train.loc[(df_cleaned_train['Diabetes'] == 'Yes'), 'Diabetes'] = 1\n",
    "df_cleaned_train.loc[(df_cleaned_train['Diabetes'] == 'No'), 'Diabetes'] = 0\n",
    "df_cleaned_train.dropna(subset=['Diabetes'], inplace=True)\n",
    "del df_cleaned_train['DiabetesAge']\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['HealthGen'])), 'HealthGen'] = 'Unknown'\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['DaysMentHlthBad'])) & (df_cleaned_train.flu == 1), 'DaysMentHlthBad'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['DaysMentHlthBad'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['DaysMentHlthBad'])) & (df_cleaned_train.flu == 0), 'DaysMentHlthBad'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['DaysMentHlthBad'])\n",
    "\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['LittleInterest'])), 'LittleInterest'] = 'Unknown'\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Depressed'])), 'Depressed'] = 'Unknown'\n",
    "\n",
    "# Missing values in \"nPregnancies\", \"nBabies\", \"Age1stBaby\" to 0, it isn't logical to take the average here.\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['nPregnancies'])), 'nPregnancies'] = 0\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['nBabies'])), 'nBabies'] = 0\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Age1stBaby'])), 'Age1stBaby'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['SleepHrsNight'])) & (df_cleaned_train.flu == 1), 'SleepHrsNight'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['SleepHrsNight'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['SleepHrsNight'])) & (df_cleaned_train.flu == 0), 'SleepHrsNight'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['SleepHrsNight'])\n",
    "\n",
    "df_cleaned_train.loc[(df_cleaned_train['SleepTrouble'] == 'Yes'), 'SleepTrouble'] = 1\n",
    "df_cleaned_train.loc[(df_cleaned_train['SleepTrouble'] == 'No'), 'SleepTrouble'] = 0\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['SleepTrouble'])), 'SleepTrouble'] = 0\n",
    "#df_cleaned_train.loc[(pd.isnull(df_cleaned_train['SleepTrouble'])), 'SleepTrouble'] = 'Unknown'\n",
    "\n",
    "df_cleaned_train.loc[(df_cleaned_train['PhysActive'] == 'Yes'), 'PhysActive'] = 1\n",
    "df_cleaned_train.loc[(df_cleaned_train['PhysActive'] == 'No'), 'PhysActive'] = 0\n",
    "# Maybe change this later on\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['PhysActive'])), 'PhysActive'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['PhysActiveDays'])), 'PhysActiveDays'] = 0\n",
    "\n",
    "for index, row in df_cleaned_train.iterrows():\n",
    "    df_cleaned_train.loc[index,'TVHrsDay'] = str(row['TVHrsDay']).replace(\"More_4_hr\", \"5\")\n",
    "    df_cleaned_train.loc[index,'CompHrsDay'] = str(row['CompHrsDay']).replace(\"More_4_hr\", \"5\")\n",
    "for index, row in df_cleaned_train.iterrows():\n",
    "    df_cleaned_train.loc[index,'TVHrsDay'] = re.sub('[A-Za-z_]', '', str(row['TVHrsDay']))\n",
    "    df_cleaned_train.loc[index,'CompHrsDay'] = re.sub('[A-Za-z_]', '', str(row['CompHrsDay']))\n",
    "\n",
    "df_cleaned_train['TVHrsDay'] = pd.to_numeric(df_cleaned_train['TVHrsDay'], errors='coerce')\n",
    "df_cleaned_train['CompHrsDay'] = pd.to_numeric(df_cleaned_train['CompHrsDay'], errors='coerce')\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['TVHrsDay'])) & (df_cleaned_train.flu == 1), 'TVHrsDay'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['TVHrsDay'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['TVHrsDay'])) & (df_cleaned_train.flu == 0), 'TVHrsDay'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['TVHrsDay'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['CompHrsDay'])) & (df_cleaned_train.flu == 1), 'CompHrsDay'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 1]['CompHrsDay'])\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['CompHrsDay'])) & (df_cleaned_train.flu == 0), 'CompHrsDay'] = fillNaN_with_unifrand(df_cleaned_train[df_cleaned_train.flu == 0]['CompHrsDay'])\n",
    "\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['TVHrsDay'])), 'TVHrsDay'] = 'Unknown'\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['CompHrsDay'])), 'CompHrsDay'] = 'Unknown'\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['TVHrsDayChild'])), 'TVHrsDayChild'] = 0\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['CompHrsDayChild'])), 'CompHrsDayChild'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(df_cleaned_train['Alcohol12PlusYr'] == 'Yes'), 'Alcohol12PlusYr'] = 1\n",
    "df_cleaned_train.loc[(df_cleaned_train['Alcohol12PlusYr'] == 'No'), 'Alcohol12PlusYr'] = 0\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Alcohol12PlusYr'])), 'Alcohol12PlusYr'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['AlcoholDay'])), 'AlcoholDay'] = 0\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['AlcoholYear'])), 'AlcoholYear'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(df_cleaned_train['SmokeNow'] == 'Yes'), 'SmokeNow'] = 1\n",
    "df_cleaned_train.loc[(df_cleaned_train['SmokeNow'] == 'No'), 'SmokeNow'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(df_cleaned_train['Smoke100'] == 'Yes'), 'Smoke100'] = 1\n",
    "df_cleaned_train.loc[(df_cleaned_train['Smoke100'] == 'No'), 'Smoke100'] = 0\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Smoke100'])), 'Smoke100'] = 0\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Smoke100n'])) & (df_cleaned_train['Smoke100'] == 1), 'Smoke100n'] = 'Smoker'\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Smoke100n'])), 'Smoke100n'] = 'Unknown'\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['SmokeNow'])) & (df_cleaned_train['Smoke100n'] == 'Smoker'), 'SmokeNow'] = 1\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['SmokeNow'])), 'SmokeNow'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['SmokeAge'])), 'SmokeAge'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(df_cleaned_train['Marijuana'] == 'Yes'), 'Marijuana'] = 1\n",
    "df_cleaned_train.loc[(df_cleaned_train['Marijuana'] == 'No'), 'Marijuana'] = 0\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['Marijuana'])), 'Marijuana'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['AgeFirstMarij'])), 'AgeFirstMarij'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(df_cleaned_train['RegularMarij'] == 'Yes'), 'RegularMarij'] = 1\n",
    "df_cleaned_train.loc[(df_cleaned_train['RegularMarij'] == 'No'), 'RegularMarij'] = 0\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['RegularMarij'])), 'RegularMarij'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['AgeRegMarij'])), 'AgeRegMarij'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(df_cleaned_train['HardDrugs'] == 'Yes'), 'HardDrugs'] = 1\n",
    "df_cleaned_train.loc[(df_cleaned_train['HardDrugs'] == 'No'), 'HardDrugs'] = 0\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['HardDrugs'])), 'HardDrugs'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(df_cleaned_train['SexEver'] == 'Yes'), 'SexEver'] = 1\n",
    "df_cleaned_train.loc[(df_cleaned_train['SexEver'] == 'No'), 'SexEver'] = 0\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['SexEver'])), 'SexEver'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['SexAge'])), 'SexAge'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['SexNumPartnLife'])), 'SexNumPartnLife'] = 0\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['SexNumPartYear'])), 'SexNumPartYear'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(df_cleaned_train['SameSex'] == 'Yes'), 'SameSex'] = 1\n",
    "df_cleaned_train.loc[(df_cleaned_train['SameSex'] == 'No'), 'SameSex'] = 0\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['SameSex'])), 'SameSex'] = 0\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['SexOrientation'])), 'SexOrientation'] = 'Unknown'\n",
    "\n",
    "df_cleaned_train.loc[(pd.isna(df_cleaned_train['PregnantNow'])), 'PregnantNow'] = 0\n",
    "df_cleaned_train.loc[df_cleaned_train['PregnantNow'] == 'Unknown', 'PregnantNow'] = 0\n",
    "df_cleaned_train.loc[(df_cleaned_train['PregnantNow'] == 'Yes'), 'PregnantNow'] = 1\n",
    "df_cleaned_train.loc[(df_cleaned_train['PregnantNow'] == 'No'), 'PregnantNow'] = 0\n",
    "\n",
    "df_cleaned_train['Gender'] = pd.to_numeric(df_cleaned_train['Gender'])\n",
    "df_cleaned_train['Diabetes'] = pd.to_numeric(df_cleaned_train['Diabetes'])\n",
    "df_cleaned_train['SleepTrouble'] = pd.to_numeric(df_cleaned_train['SleepTrouble'])\n",
    "df_cleaned_train['PhysActive'] = pd.to_numeric(df_cleaned_train['PhysActive'])\n",
    "df_cleaned_train['Alcohol12PlusYr'] = pd.to_numeric(df_cleaned_train['Alcohol12PlusYr'])\n",
    "df_cleaned_train['SmokeNow'] = pd.to_numeric(df_cleaned_train['SmokeNow'])\n",
    "df_cleaned_train['Smoke100'] = pd.to_numeric(df_cleaned_train['Smoke100'])\n",
    "df_cleaned_train['Marijuana'] = pd.to_numeric(df_cleaned_train['Marijuana'])\n",
    "df_cleaned_train['RegularMarij'] = pd.to_numeric(df_cleaned_train['RegularMarij'])\n",
    "df_cleaned_train['HardDrugs'] = pd.to_numeric(df_cleaned_train['HardDrugs'])\n",
    "df_cleaned_train['SexEver'] = pd.to_numeric(df_cleaned_train['SexEver'])\n",
    "df_cleaned_train['SameSex'] = pd.to_numeric(df_cleaned_train['SameSex'])\n",
    "df_cleaned_train['PregnantNow'] = pd.to_numeric(df_cleaned_train['PregnantNow'])\n",
    "df_cleaned_train['TVHrsDay'] = pd.to_numeric(df_cleaned_train['TVHrsDay'])\n",
    "df_cleaned_train['CompHrsDay'] = pd.to_numeric(df_cleaned_train['CompHrsDay'])\n",
    "\n",
    "df_cleaned_train.info()\n",
    "df_cleaned_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_train = df_cleaned_train.append(pd.get_dummies(df_cleaned_train[['Race1', 'Education', 'MaritalStatus', 'HomeOwn', 'Work', 'HealthGen', 'LittleInterest', 'Depressed', 'TVHrsDay', 'CompHrsDay', 'Smoke100n', 'SexOrientation', 'PregnantNow']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_del = ['Race1', 'Education', 'MaritalStatus', 'HomeOwn', 'Work', 'HealthGen', 'LittleInterest', 'Depressed', 'TVHrsDay', 'CompHrsDay', 'Smoke100n', 'SexOrientation', 'PregnantNow']\n",
    "for itm in list_del:\n",
    "    del df_cleaned_train[itm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                             0.169576\n",
       "Gender                         0.091608\n",
       "Age                            0.191956\n",
       "HHIncomeMid                    0.079432\n",
       "Poverty                        0.090110\n",
       "HomeRooms                      0.132002\n",
       "Weight                         0.168377\n",
       "Height                         0.168211\n",
       "BMI                            0.183584\n",
       "Pulse                          0.171356\n",
       "BPSysAve                       0.185493\n",
       "BPDiaAve                       0.165249\n",
       "BPSys1                         0.187250\n",
       "BPDia1                         0.169794\n",
       "BPSys2                         0.187334\n",
       "BPDia2                         0.166053\n",
       "BPSys3                         0.185360\n",
       "BPDia3                         0.159827\n",
       "Testosterone                   0.074010\n",
       "DirectChol                     0.150011\n",
       "TotChol                        0.174593\n",
       "UrineVol1                      0.112272\n",
       "UrineFlow1                     0.080421\n",
       "Diabetes                       0.134901\n",
       "DaysMentHlthBad                0.255299\n",
       "nPregnancies                   0.116687\n",
       "nBabies                        0.109860\n",
       "Age1stBaby                     0.101815\n",
       "SleepHrsNight                  0.143035\n",
       "SleepTrouble                   0.170179\n",
       "PhysActive                     0.011041\n",
       "PhysActiveDays                 0.050053\n",
       "TVHrsDayChild                  0.024810\n",
       "CompHrsDayChild                0.037162\n",
       "Alcohol12PlusYr                0.120305\n",
       "AlcoholDay                     0.057342\n",
       "AlcoholYear                    0.057761\n",
       "SmokeNow                       0.086870\n",
       "Smoke100                       0.130466\n",
       "SmokeAge                       0.121165\n",
       "Marijuana                      0.063028\n",
       "AgeFirstMarij                  0.059787\n",
       "RegularMarij                   0.066986\n",
       "AgeRegMarij                    0.074842\n",
       "HardDrugs                      0.064116\n",
       "SexEver                        0.106751\n",
       "SexAge                         0.093142\n",
       "SexNumPartnLife                0.035233\n",
       "SexNumPartYear                 0.014337\n",
       "SameSex                        0.063300\n",
       "flu                            1.000000\n",
       "Race1_Black                   -0.048895\n",
       "Race1_Hispanic                -0.032274\n",
       "Race1_Mexican                 -0.043528\n",
       "Race1_Other                   -0.037836\n",
       "Race1_White                   -0.110552\n",
       "Education_8th Grade           -0.027024\n",
       "Education_9 - 11th Grade      -0.037210\n",
       "Education_College Grad        -0.058185\n",
       "Education_High School         -0.050027\n",
       "Education_No Degree           -0.058361\n",
       "Education_Some College        -0.060097\n",
       "Education_Unknown             -0.038170\n",
       "MaritalStatus_Divorced        -0.031723\n",
       "MaritalStatus_LivePartner     -0.028768\n",
       "MaritalStatus_Married         -0.084062\n",
       "MaritalStatus_NeverMarried    -0.047102\n",
       "MaritalStatus_Separated       -0.017707\n",
       "MaritalStatus_Unknown         -0.072098\n",
       "MaritalStatus_Widowed         -0.027783\n",
       "HomeOwn_Other                 -0.018635\n",
       "HomeOwn_Own                   -0.117435\n",
       "HomeOwn_Rent                  -0.079845\n",
       "Work_Looking                  -0.022131\n",
       "Work_NotWorking               -0.070485\n",
       "Work_Unknown                  -0.063556\n",
       "Work_Working                  -0.093331\n",
       "HealthGen_Excellent           -0.037500\n",
       "HealthGen_Fair                -0.040444\n",
       "HealthGen_Good                -0.073008\n",
       "HealthGen_Poor                -0.016115\n",
       "HealthGen_Unknown             -0.065247\n",
       "HealthGen_Vgood               -0.064487\n",
       "LittleInterest_Most           -0.025104\n",
       "LittleInterest_None           -0.100952\n",
       "LittleInterest_Several        -0.041432\n",
       "LittleInterest_Unknown        -0.079359\n",
       "Depressed_Most                -0.024339\n",
       "Depressed_None                -0.102094\n",
       "Depressed_Several             -0.040308\n",
       "Depressed_Unknown             -0.079267\n",
       "Smoke100n_Non-Smoker          -0.087399\n",
       "Smoke100n_Smoker              -0.073102\n",
       "Smoke100n_Unknown             -0.072098\n",
       "SexOrientation_Bisexual       -0.013638\n",
       "SexOrientation_Heterosexual   -0.093713\n",
       "SexOrientation_Homosexual     -0.011223\n",
       "SexOrientation_Unknown        -0.103969\n",
       "Name: flu, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del df_cleaned_train[['Race1', 'Education', 'MaritalStatus', 'HomeOwn', 'Work', 'HealthGen', 'LittleInterest', 'Depressed', 'TVHrsDay', 'CompHrsDay', 'Smoke100n', 'SexOrientation', 'PregnantNow']]\n",
    "df_cleaned_train.fillna(0, inplace=True)\n",
    "df_cleaned_train.corr()['flu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "df_test = pd.read_csv('data/flu_test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c4fbf5e236b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x train shape:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "#What's up in each set\n",
    "\n",
    "x = df.values[:, :-1]\n",
    "y = df.values[:, -1]\n",
    "\n",
    "x_test = df_test.values[:, :-1]\n",
    "\n",
    "print('x train shape:', x.shape)\n",
    "print('x test shape:', x_test.shape)\n",
    "print('train class 0: {}, train class 1: {}'.format(len(y[y==0]), len(y[y==1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model Choice\n",
    "\n",
    "The first task is to decide which classifier to use (from the ones that we learned this block), i.e. which one would best suit our task and our data. Note that our data are heavily unbalanced, thus you need to do some exploration on how different classifiers handle inbalances in the data (we will discuss some of these techniques during week 3 lecture).\n",
    "\n",
    "It would be possible to do brute force model comparison here - i.e. tune all models and compare which does best with respect to various benchmarks. However, it is also reasonable to do a first round of model comparison by running models (with out of the box parameter settings) on the training data and eliminating some models which performed very poorly.\n",
    "\n",
    "Let the best model win!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_score(model, x_test, y_test):\n",
    "    overall = 0\n",
    "    class_0 = 0\n",
    "    class_1 = 0\n",
    "    for i in range(100):\n",
    "        sample = np.random.choice(len(x_test), len(x_test))\n",
    "        x_sub_test = x_test[sample]\n",
    "        y_sub_test = y_test[sample]\n",
    "        \n",
    "        overall += model.score(x_sub_test, y_sub_test)\n",
    "        class_0 += model.score(x_sub_test[y_sub_test==0], y_sub_test[y_sub_test==0])\n",
    "        class_1 += model.score(x_sub_test[y_sub_test==1], y_sub_test[y_sub_test==1])\n",
    "\n",
    "    return pd.Series([overall / 100., \n",
    "                      class_0 / 100.,\n",
    "                      class_1 / 100.],\n",
    "                      index=['overall accuracy', 'accuracy on class 0', 'accuracy on class 1'])\n",
    "\n",
    "score = lambda model, x_test, y_test: pd.Series([model.score(x_test, y_test), \n",
    "                                                 model.score(x_test[y_test==0], y_test[y_test==0]),\n",
    "                                                 model.score(x_test[y_test==1], y_test[y_test==1])], \n",
    "                                                index=['overall accuracy', 'accuracy on class 0', 'accuracy on class 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(df, random_state=0):\n",
    "    # Better way with stratify:\n",
    "    itrain, itest = train_test_split(range(df.shape[0]), test_size=0.25, random_state=random_state, stratify=df['flu'])\n",
    "\n",
    "    gsstemp = df_cleaned_train[['ID', 'Gender', 'Age', 'HHIncomeMid', 'Poverty', 'HomeRooms', 'Weight',\n",
    "'Height', 'BMI', 'Pulse', 'BPSysAve', 'BPDiaAve', 'BPSys1', 'BPDia1',\n",
    "'BPSys2', 'BPDia2', 'BPSys3', 'BPDia3', 'Testosterone', 'DirectChol',\n",
    "'TotChol', 'UrineVol1', 'UrineFlow1', 'Diabetes', 'DaysMentHlthBad',\n",
    "'nPregnancies', 'nBabies', 'Age1stBaby', 'SleepHrsNight',\n",
    "'SleepTrouble', 'PhysActive', 'PhysActiveDays', 'TVHrsDayChild',\n",
    "'CompHrsDayChild', 'Alcohol12PlusYr', 'AlcoholDay', 'AlcoholYear',\n",
    "'SmokeNow', 'Smoke100', 'SmokeAge', 'Marijuana', 'AgeFirstMarij',\n",
    "'RegularMarij', 'AgeRegMarij', 'HardDrugs', 'SexEver', 'SexAge',\n",
    "'SexNumPartnLife', 'SexNumPartYear', 'SameSex', 'Race1_Black',\n",
    "'Race1_Hispanic', 'Race1_Mexican', 'Race1_Other', 'Race1_White',\n",
    "'Education_8th Grade', 'Education_9 - 11th Grade',\n",
    "'Education_College Grad', 'Education_High School',\n",
    "'Education_No Degree', 'Education_Some College', 'Education_Unknown',\n",
    "'MaritalStatus_Divorced', 'MaritalStatus_LivePartner',\n",
    "'MaritalStatus_Married', 'MaritalStatus_NeverMarried',\n",
    "'MaritalStatus_Separated', 'MaritalStatus_Unknown',\n",
    "'MaritalStatus_Widowed', 'HomeOwn_Other', 'HomeOwn_Own', 'HomeOwn_Rent',\n",
    "'Work_Looking', 'Work_NotWorking', 'Work_Unknown', 'Work_Working',\n",
    "'HealthGen_Excellent', 'HealthGen_Fair', 'HealthGen_Good',\n",
    "'HealthGen_Poor', 'HealthGen_Unknown', 'HealthGen_Vgood',\n",
    "'LittleInterest_Most', 'LittleInterest_None', 'LittleInterest_Several',\n",
    "'LittleInterest_Unknown', 'Depressed_Most', 'Depressed_None',\n",
    "'Depressed_Several', 'Depressed_Unknown', 'Smoke100n_Non-Smoker',\n",
    "'Smoke100n_Smoker', 'Smoke100n_Unknown', 'SexOrientation_Bisexual',\n",
    "'SexOrientation_Heterosexual', 'SexOrientation_Homosexual',\n",
    "'SexOrientation_Unknown']]\n",
    "\n",
    "    X_train = gsstemp.iloc[itrain, :]\n",
    "    X_test = gsstemp.iloc[itest, :]\n",
    "    y_train = df['flu'].iloc[itrain]\n",
    "    y_test = df['flu'].iloc[itest]\n",
    "\n",
    "    print(\"Number of sick people in test set: \",len(y_test[y_test == 1]))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sick people in test set:  67\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test(df_cleaned_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iris' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-368717a40d92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'iris' is not defined"
     ]
    }
   ],
   "source": [
    "### fancy models that solve the problem\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "cross_val_score(clf, iris.data, iris.target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On evaluation\n",
    "\n",
    "### AUROC\n",
    "\n",
    "As mentioned abbove, we will use the accuracy scores for each class and for the whole dataset, as well as the AUROC score from Kaggle platform. You can coimpute AUROC locally (e.g. on your train/validation set) by calling the relevant scikit learn function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###AUROC locally\n",
    "\n",
    "#score = roc_auc_score(real_labels, predicted_labels)\n",
    "\n",
    "#real_labels: the ground truth (0 or 1)\n",
    "#predicted_labels: labels predicted by your algorithm (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy (per class)\n",
    "\n",
    "Below there is a function that will be handy for your models. It computes the accuracy per-class, based on a model you pass as parameter and a dataset (split to x/y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extended_score(model, x_test, y_test):\n",
    "    overall = 0\n",
    "    class_0 = 0\n",
    "    class_1 = 0\n",
    "    for i in range(100):\n",
    "        sample = np.random.choice(len(x_test), len(x_test))\n",
    "        x_sub_test = x_test[sample]\n",
    "        y_sub_test = y_test[sample]\n",
    "        \n",
    "        overall += model.score(x_sub_test, y_sub_test)\n",
    "        class_0 += model.score(x_sub_test[y_sub_test==0], y_sub_test[y_sub_test==0])\n",
    "        class_1 += model.score(x_sub_test[y_sub_test==1], y_sub_test[y_sub_test==1])\n",
    "\n",
    "    return pd.Series([overall / 100., \n",
    "                      class_0 / 100.,\n",
    "                      class_1 / 100.],\n",
    "                      index=['overall accuracy', 'accuracy on class 0', 'accuracy on class 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same job as before, but faster?\n",
    "\n",
    "score = lambda model, x_val, y_val: pd.Series([model.score(x_val, y_val), \n",
    "                                                 model.score(x_val[y_val==0], y_val[y_val==0]),\n",
    "                                                 model.score(x_val[y_val==1], y_val[y_val==1])], \n",
    "                                                index=['overall accuracy', 'accuracy on class 0', 'accuracy on class 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution extraction for Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you extract your solutions (predictions) in the correct format required by Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Conclusions\n",
    "\n",
    "Highlight at the end of your notebook, which were the top-3 approaches that produced the best scores for you. That is, provide a table with the scores you got (on the AUROC score you get from Kaggle) and make sure that you judge these in relation to your work on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
